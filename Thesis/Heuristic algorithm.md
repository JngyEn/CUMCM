*现代优化算法是 20世纪 80年代初兴起的启发式算法*
这些算法在理论和实际应用方面得到了较大的发展。无论这些算法是怎样产生的，它们都有一个共同的目标—求 NP-hard 组合优化问题的全局最优解。虽然有这些目标，但 NP-hard 理论限制它们只能以启发式的算法去求解实际问题。
### 模拟退火算法
#### 理论
考虑这样一个组合优化问题: 优化函数为$f:x\rightarrow R^+$，其中$x∈S$，它表示优化问题的一个可行解，S表示函数的定义域。$N(x)\subseteq S$表示x的一个邻域集合。
首先给定一个初始温度$T_0$。和该优化问题的一个初始解$x(0)$，并由$x(0)$生成下一个解$x'\in N(x(0))$，是否接受$x'$作为一个新解$x(1)$依赖于如下概率∶
$$
P(x(0)\rightarrow x')=\begin{cases}
1,f(x')<f(x(0))\\
e^{-{f(x')-f(x(0)) \over T_0}}, otherwise
\end{cases}
$$
如果温度下降十分缓慢，而在每个温度都有足够多次的状态转移，使之在每一个温度下达到热平衡，则全局最优解将以概率1被找到。因此可以说模拟退火算法可以找到全局最优解
#### 在模拟退火算法中应注意以下问题
- (1)理论上，降温过程要足够缓慢，要使得在每一温度下达到热平衡。在计算机实现中，如果降温速度过缓，所得到的解的性能会较为令人满意，但是算法会太慢, 相对于简单的搜索算法不其有明显优势。如果降温速度过快，则很可能最终得不到全局最优解。因此使用时要综合考虑解的性能和算法速度，在两者之间采取一种折中。
- (2)要确定在每一温度下状态转换的结束准则。实际操作可以考虑当连续 m 次的 转换过程没有使状态发生变化时结束该温度下的状态转换。最终温度的确定可以提前定为一个较小的值$T_e$，或连续几个温度下转换过程没有使状态发生变化算法就结束。 
- (3)选择初始温度和确定某个可行解的邻域的方法也要恰当。
- (4)先使用蒙特卡洛方法求得一个较好的初始解
#### 例子
[[example 2]]
### 遗传算法
#### 理论
遗传算法（Genetic Algorithms，GA）是一种基于自然选择原理和自然遗传机制的搜索 （寻优）算法、它是模拟自然界中的生命进化机制。在人工系统中实现特定目标的优化。 遗传算法的实质是通过群体搜索技术，根据适者生存的原则逐代进化，最终得到最优解或 准最优解。它必须做以下操作: 初始群体的产生、求每一个体的适应度、根据适者生存的原则选择优良个体、被选出的优良个体两两配对，通过随机交叉其染色体的基因并随机变 异某些染色体的基因生成下一代群体，按此方法使群体逐代进化，直到满足进化终止条 件。其实现方法如下∶ 
- （1）根据具体问题确定可行解城，确定一种编码方法，能用数值串或字符串表示可行解域的每一解。 
- （2）对每一解应有一个度量好坏的依据, 它用一函数表示，叫做适应度函数，一般由目标函数构成。 
- （3）确定进化参数群体规模 $M$、交叉概率$p_c$、变异概率$p_m$、进化终止条件。

| 生物遗传概念 | 遗传算法中的作用                |
| :----: | :---------------------- |
|  适者生存  | 算法停止时，最优目标值的可行解有最大可能被留住 |
|   个体   | 可行解                     |
|  染色体   | 可行解的编码                  |
|   基因   | 可行解中每一分量的特征             |
|  适应性   | 适应度函数值                  |
|   种群   | 根据适应度函数值选取的一组可行解        |
|   交配   | 通过选交配原则产生一组新可行解的过程      |
|   变异   | 编码的某一分量发生变化的过程          |
#### 应用思路
针对[[example 2]]中的问题,求解的遗传算法的参数设定如下∶ 
- 种群大小$M=50$
- 最大代数$G=1000$
- 交叉率$p_c=1$，交叉概率为1能保证种群的充分进化
##### 初始种群
先利用经典的近似算法——改良圈算法求得一个较好的初始种群。
##### 目标函数
目标函数为侦寨所有目标的路径长度，适应度函数就取为目标函数
$$
min\ f(\pi_1,\pi_2,\ldots,\pi_102)=\sum_{i=1}^{101} d_{\pi_i\pi_{i+1}}
$$
##### 交叉操作
交叉操作采用单点交叉。对于选定的两个父代个体$f_1=\omega_1\omega_2\ldots\omega_{102},f_2=\omega_1'\omega_2'\ldots\omega_{102}'$随机地选取第t个基因处为交叉点，则经过交叉运算后得到的子代个体为$s_1$和$s_2$，$s_1$的基因由$f_1$的前t个基因和$f_2$的后102-t个基因构成，$s_2$的基因由$f_2$的前t个基因和$f_1$的后102-t个基因构成
##### 变异操作
变异也是实现群体多样性的一种手段，同时也是全局寻优的保证。
参考[[example 2#求解的模拟退火算法描述]]中的3变换法进行变异
##### 选择
采用确定性的选择策略，也就是在父代种群和子代种群中选择目标函数值最小的 $M$ 个个体进化到下一代，这样可以保证父代的优良特性被保存下来。
#### 可能的改进方法
- 交叉"门当户对": 这可以削弱避免遗传算法在组合优化应用中 产生的寻优抖振问题，可以提高算法收敛精度。
### 粒子群算法
粒子群优化算法（Particle Swarm Optimization，简称 PSO）是一种基于群体智能的优化算法，由 Kennedy 和 Eberhart 于 1995 年提出。PSO 是模拟鸟群觅食等群体行为的一种算法，具有简单、易于实现的特点，广泛应用于函数优化、神经网络训练、组合优化等领域。
#### 理论
PSO 的基本思想是通过群体中粒子间的信息共享，使群体向着最优解区域移动。算法通过不断更新粒子的速度和位置，最终找到问题的最优解。
##### 基本概念
- **粒子（Particle）**：在 PSO 中，每个解被看作是一个“粒子”，在搜索空间中飞行。粒子的当前位置表示一个可能的解。
- **速度（Velocity）**：粒子在搜索空间中的飞行速度，决定了粒子下一步的位置。
- **适应度函数（Fitness Function）**：用于评价粒子位置的好坏，即解的优劣程度。
- **个体极值（Pbest）**：粒子自身迄今为止找到的最优位置。
- **全局极值（Gbest）**：整个群体中迄今为止找到的最优位置。
#### 应用思路
1. **初始化**：随机生成粒子的初始位置和速度，并计算每个粒子的适应度值，确定初始的个体极值（Pbest）和全局极值（Gbest）。
2. **更新速度和位置**：
    每个粒子的速度根据自身的历史最优位置（Pbest）和全局最优位置（Gbest）进行更新。
$$
v_i^{t+1}​=w⋅v_i^t​+c1​⋅r1​⋅(Pbest_i​−x_i^t​)+c2​⋅r2​⋅(Gbest−x_i^t​)
$$
    其中$r_1$与$r_2$是$[0,1]$的随机数, 用于引入随机性
    位置更新公式：
$$
x_i^{t+1}=x_i^t+v_i^{t+1}
$$
3. **更新个体极值和全局极值**：根据新的位置计算适应度，如果粒子的当前位置优于它的历史最优位置，则更新个体极值。如果粒子群中某一粒子的当前位置优于全局最优位置，则更新全局极值。

4. **判断终止条件**：一般是达到最大迭代次数或全局最优解在连续几代中没有显著变化时停止迭代。

5. **输出最优解**：迭代结束后，输出全局最优解及其对应的适应度值。
#### python实现示例
```python
import numpy as np
# 定义适应度函数
def fitness(x):
    return x**2
# 粒子群算法
def pso(n_particles, dimensions, iterations):
    # 初始化粒子位置和速度
    particles = np.random.uniform(-10, 10, (n_particles, dimensions))
    velocities = np.random.uniform(-1, 1, (n_particles, dimensions))
    # 初始化个体极值和全局极值
    pbest = particles.copy()
    gbest = pbest[np.argmin([fitness(p) for p in pbest])]
    # 参数设置
    w = 0.5  # 惯性权重
    c1 = 1.0  # 个体学习因子
    c2 = 2.0  # 群体学习因子
    # 迭代优化
    for _ in range(iterations):
        for i in range(n_particles):
            # 更新速度和位置
            r1, r2 = np.random.rand(), np.random.rand()
            velocities[i] = (w * velocities[i] +
                             c1 * r1 * (pbest[i] - particles[i]) +
                             c2 * r2 * (gbest - particles[i]))
            particles[i] += velocities[i]
            
            # 更新个体极值
            if fitness(particles[i]) < fitness(pbest[i]):
                pbest[i] = particles[i]
        
        # 更新全局极值
        gbest = pbest[np.argmin([fitness(p) for p in pbest])]
    return gbest, fitness(gbest)
# 执行粒子群算法
best_position, best_fitness = pso(n_particles=30, dimensions=1, iterations=100)
print("最优位置:", best_position)
print("最优适应度值:", best_fitness)
```

### 启发式算法的选择
#### 1. 遗传算法（Genetic Algorithm, GA）
- **优点**：
    - **全局搜索能力强**：GA 通过种群进化能够有效探索大范围的解空间，减少陷入局部最优的可能。
    - **适应多种问题类型**：适用于离散、连续、混合优化问题。
    - **无需梯度信息**：不需要目标函数的导数信息，因此可以处理不连续、不可微的目标函数。
- **缺点**：
    - **收敛速度较慢**：由于其随机性，GA 收敛到最优解可能需要较多的迭代次数。
    - **参数调优复杂**：选择合适的种群大小、交叉概率和变异概率需要经验和实验。
    - **可能早熟收敛**：可能在搜索早期陷入局部最优解，尤其是选择策略不当时。
- **适用场景**：
    - 复杂的组合优化问题（如旅行商问题、调度问题）。
    - 无法使用梯度优化方法的问题。
    - 需要探索广泛解空间的问题。

#### 2. 模拟退火（Simulated Annealing, SA）
- **优点**：
    - **跳出局部最优的能力**：通过温度参数的控制，SA 可以以一定概率接受较差解，从而避免局部最优。
    - **简单易实现**：SA 算法的实现相对简单，参数少且容易理解。
    - **全局收敛性**：在理论上，随着温度降低，SA 可以收敛到全局最优解。
- **缺点**：
    - **收敛速度取决于温度下降策略**：过快或过慢的降温都会影响算法的效率和效果。
    - **效率较低**：SA 逐步探索的方式使得其收敛速度较慢，尤其在高维问题中。
- **适用场景**：
    - 需要从局部最优跳出，探索全局最优解的问题。
    - 高维、复杂的优化问题，尤其是在不容易构建有效启发式的场景中。
#### 3. 粒子群优化（Particle Swarm Optimization, PSO）
- **优点**：
    - **算法简单**：PSO 公式简单，易于理解和实现，参数较少。
    - **全局搜索能力**：通过群体协作和信息共享，PSO 能有效探索解空间，具有较强的全局搜索能力。
    - **参数调节相对容易**：相比于其他启发式算法，PSO 的参数（惯性权重、学习因子）较少且调节相对简单。
- **缺点**：
    - **易陷入局部最优**：在高维复杂问题中，PSO 可能会在早期阶段收敛到局部最优解。
    - **收敛速度依赖参数设置**：PSO 的表现高度依赖惯性权重和学习因子的选择，不当的参数设置可能导致收敛缓慢或搜索效率低。
- **适用场景**：
    - 连续优化问题、函数优化问题。
    - 无法获得目标函数的导数信息或计算导数代价高的问题。
    - 多目标优化、需要同时考虑多个优化目标的问题。
#### 选择启发式算法的建议
1. **问题类型**：根据问题是离散的、连续的、组合优化还是函数优化，选择适合的算法。例如，离散问题通常选择~~蚁群算法~~或~~禁忌搜索~~，连续问题则可以选择粒子群优化或遗传算法。

2. **搜索空间维度**：高维问题通常需要具有强大全局搜索能力的算法，如遗传算法或粒子群优化，而在低维或结构明确的问题中，~~禁忌搜索~~或模拟退火可能更高效。

3. **全局 vs 局部搜索**：如果问题容易陷入局部最优解，选择具有全局搜索能力的算法，如遗传算法或~~蚁群算法~~；如果需要精确搜索局部最优解，则可以考虑~~禁忌搜索~~或模拟退火。

4. **计算资源与时间**：遗传算法、~~蚁群算法~~可能需要较多的计算资源和时间，而模拟退火和~~禁忌搜索~~相对较轻量，适合资源有限或实时性要求高的场景。

5. **复杂性与可调性**：对于简单问题，选择易于实现、调参较少的算法，如粒子群优化。对于复杂问题，可以选择参数可调性强的遗传算法或~~蚁群算法~~，以获得更好的性能。

